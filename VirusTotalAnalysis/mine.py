"""
Find files.

Problem
-------
- Search function has a limit of 300 results.
- Subsequent calls to the search function return the same 300 results.
- Using the cursor argument to get the next 300 results does not work.
"""

from argparse import ArgumentParser
from datetime import datetime
from pathlib import Path
from pprint import pprint
import sys
from typing import Optional

import requests
from tqdm import tqdm

from cfg import KEY
from report import wait_until_midnight, QUOTA_EXCEEDED_ERROR, SUCCESS


LIMIT = 300


def OptionalPath(s):
    if s is None:
        return None
    return Path(s)


def get_url(
    query: str,
    limit: Optional[int] = None,
    descriptors_only: bool = True,
    cursor: Optional[int] = None,
) -> str:
    url = f"https://www.virustotal.com/api/v3/search?query={query}"
    if cursor:
        url += f"&cursor={cursor}"
    else:
        if descriptors_only:
            url += "&descriptors_only=true"
        if limit:
            url += f"&limit={limit}"
    return url


def get_response(url, headers) -> requests.Response:
    response = requests.get(url, headers=headers)
    if response.status_code == QUOTA_EXCEEDED_ERROR:
        print("Waiting until midnight UTC...")
        wait_until_midnight()
        response = requests.get(url, headers=headers)

    if response.status_code != SUCCESS:
        print(f"Error: {response.status_code=}")
        pprint(response.json())
        sys.exit(1)

    return response


def process_response(response: requests.Response) -> tuple[list[str], str]:
    res = response.json()
    try:
        cursor = res["meta"]["cursor"]
    except KeyError:
        print("No meta data for next cursor.")
        cursor = None

    shas = []
    for sample in res["data"]:
        s = sample["id"].split("-")[1]
        shas.append(s)

    return shas, cursor


def main(query: str, outfile: Path, limit: Optional[int] = None) -> None:

    def write(shas: list[str]):
        with open(outfile, "a") as fp:
            fp.writelines("\n".join(shas) + "\n")


    headers = {"accept": "application/json", "x-apikey": KEY}

    if limit < 300:
        url = get_url(query, limit)
        response = get_response(url, headers)
        shas, _ = process_response(response)
        write(shas)
        return

    cursor = None
    iters, last_iter_limit = divmod(limit, LIMIT)
    iters = iters + 1 if last_iter_limit else iters
    print(f"{iters=}")
    print(f"{last_iter_limit=}")
    for i in tqdm(list(range(iters))):
        _limit = last_iter_limit if (i == iters - 1 and limit != 300) else LIMIT
        url = get_url(query, _limit, True, cursor)
        print(url)
        response = get_response(url, headers)
        shas, cursor = process_response(response)
        write(shas)
        if cursor is None:
            break


def cli() -> None:
    parser = ArgumentParser(description="Find files.")
    parser.add_argument(
        "--query",
        type=str,
        help="The query to search for on VirusTotal. For example, 'macho' or 'elf.",
    )
    parser.add_argument(
        "--outfile",
        type=OptionalPath,
        default=None,
        help="The file to write results to. Defaults to `./{query}.txt`.",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=1,
        help="The maximum number of results to return.",
    )
    args = parser.parse_args()

    if not args.outfile:
        args.outfile = Path("./" + args.query + ".txt")
    if args.outfile.exists():
        print(f"Error: {args.outfile} already exists.")
        sys.exit(1)

    main(args.query, args.outfile, args.limit)


if __name__ == "__main__":
    #main("macho", Path("./macho.txt"), 1000)
    cli()
